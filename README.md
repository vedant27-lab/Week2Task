# ğŸš€ Week 2 â€“ Machine Learning Projects by Vedant Patil

This repository contains my Week 2 internship work at **CyArt**, covering 4 individual tasks related to machine learning, deep learning foundations, time series processing, and model-based predictions.

Each task was built **step-by-step from scratch** and demonstrates both my technical learning and practical application.

---

## ğŸ“ Folder Structure

Week2-Tasks/
â”œâ”€â”€ Task1/
â”‚ â”œâ”€â”€ train.ipynb
â”‚ â”œâ”€â”€ model.py
â”‚ â”œâ”€â”€ Loss Curve.png
â”‚ â”œâ”€â”€ Model Output.png
â”‚ â””â”€â”€ Readme.md
â”‚
â”œâ”€â”€ Task2/
â”‚ â”œâ”€â”€ app.py
â”‚ â”œâ”€â”€ sample.txt
â”‚ â”œâ”€â”€ nlp_pipeline.py
â”‚ â”œâ”€â”€ test_requests.http
â”‚ â””â”€â”€ readme.md
â”‚
â”œâ”€â”€ Task3/
â”‚ â”œâ”€â”€ benchmark.py
â”‚ â”œâ”€â”€ final_results.csv
â”‚ â”œâ”€â”€ Filter_1.png
â”‚ â”œâ”€â”€ Benchmark_chart.png
â”‚ â”œâ”€â”€ timeseries_utils.py
â”‚ â””â”€â”€ readme.md
â”‚
â”œâ”€â”€ Task4/
â”‚ â”œâ”€â”€ cleanedData.csv
â”‚ â”œâ”€â”€ data_cleaning.ipynb
â”‚ â”œâ”€â”€ final_dataset.csv
â”‚ â”œâ”€â”€ model_r2_comparison.png
â”‚ â”œâ”€â”€ model_rmse_comparison.png
â”‚ â”œâ”€â”€ model.ipynb
â”‚ â””â”€â”€ readme.md


---

## ğŸ”¹ Task 1: Neural Network from Scratch (NumPy)

### ğŸ“Œ Objective:
Build a simple feedforward neural network from scratch using NumPy â€” no external ML libraries.

### ğŸ› ï¸ Components:
- `Layer_Dense`: Implements weights, biases, forward and backward pass
- Activations:
  - `ReLU`, `Sigmoid`
- Loss:
  - `MeanSquaredError`
- Optimizer:
  - `Stochastic Gradient Descent (SGD)`

### ğŸ“ˆ Output:
- Training loop runs with visible loss reduction
- Layer-wise backpropagation validated
- PNG graphs included: `Loss Curve`, `Model Output`

### ğŸ“ Files:
- `train.ipynb`: Full training loop
- `model.py`: Modularized NN code
- `Loss Curve.png`: Epoch loss visualization
- `Model Output.png`: Final output

---

## ğŸ”¹ Task 2: Sentiment Analysis API using Flask

### ğŸ“Œ Objective:
Create a REST API that performs sentiment classification (Positive, Negative, Neutral) on a given sentence.

### ğŸ› ï¸ Stack Used:
- `Flask` for web API
- `TextBlob` for sentiment polarity
- `Postman` for testing endpoints

### âš™ï¸ Endpoint:

- **POST /analyze**
```json
Request:
{
  "text": "The air quality is really bad."

Response:
{
  "sentiment": "negative"
}

ğŸ“ Files:
* app.py: Main Flask app
* nlp_pipeline.py: Sentiment logic
* sample.txt: For CLI input testing
* test_requests.http: Ready-to-use tests

ask 3: Rolling Mean & Variance â€“ Pandas vs NumPy
ğŸ“Œ Objective:
Compare rolling window statistics (mean/variance) between Pandas and NumPy.

ğŸ› ï¸ Functions:
rolling_stats_pandas(): Uses pandas.Series.rolling

rolling_stats_numpy(): Vectorized NumPy with cumsum

ğŸ” Insights:
NumPy version is much faster for large arrays

Results are validated to be nearly identical

ğŸ“Š Outputs:
Benchmark_chart.png: Pandas vs NumPy timing chart

Filter_1.png: Visual rolling stats

final_results.csv: Benchmarked results

ğŸ“ Files:
benchmark.py: Speed test and visualization

timeseries_utils.py: Both function definitions

readme.md: Mini README inside Task3 folder

ğŸ”¹ Task 4: AQI Prediction with ML (Delhi Dataset)
ğŸ“Œ Objective:
Train multiple ML models to predict the Air Quality Index (AQI) for Delhi using a public Kaggle dataset.

ğŸ“Š Dataset Columns:
Features: PM2.5, PM10, NO2, SO2, CO, Ozone

Date context: Month, Year, Days, Holidays_Count

Target: AQI

ğŸ”¬ Preprocessing:
Null value handling

Added feature ratios: PM_ratio, NO2_SO2_ratio

Feature scaling for linear models
| Model             | RMSE  | RÂ² Score |
| ----------------- | ----- | -------- |
| Linear Regression | 42.30 | 0.72     |
| Random Forest     | 30.70 | 0.85     |
| XGBoost           | 27.90 | 0.89     |

ğŸ† Best Performer:
XGBoost with lowest RMSE and highest RÂ².

ğŸ“ˆ Graphs:
rmse_comparison.png: RMSE Bar Chart
r2_comparison.png: RÂ² Bar Chart

ğŸ“ Files:
model.ipynb: Full pipeline in Jupyter
cleanedData.csv: Cleaned dataset used

Requirements
All tasks are based on:
Python 3.10+
NumPy, Pandas, Matplotlib, Scikit-learn, TextBlob
Flask (Task 2), XGBoost (Task 4)
You can install all dependencies using:

pip install -r requirements.txt

âœï¸ Author
Vedant Patil
Deep Learning Intern â€“ CyArt
Computer Engineering @ SPPU

